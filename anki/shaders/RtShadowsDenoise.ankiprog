// Copyright (C) 2009-2020, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki start comp

ANKI_SPECIALIZATION_CONSTANT_UVEC2(OUT_IMAGE_SIZE, 0, UVec2(1));
ANKI_SPECIALIZATION_CONSTANT_U32(SAMPLE_COUNT, 2, 1);
ANKI_SPECIALIZATION_CONSTANT_U32(PIXEL_RADIUS, 3, 1);
ANKI_SPECIALIZATION_CONSTANT_U32(SPIRAL_TURN_COUNT, 4, 1);

#include <anki/shaders/BilateralFilter.glsl>
#include <anki/shaders/Pack.glsl>

const UVec2 WORKGROUP_SIZE = UVec2(8u, 8u);
layout(local_size_x = WORKGROUP_SIZE.x, local_size_y = WORKGROUP_SIZE.y, local_size_z = 1) in;

layout(set = 0, binding = 0) uniform sampler u_linearAnyClampSampler;
layout(set = 0, binding = 1) uniform texture2DArray u_inTex;
layout(set = 0, binding = 2) uniform texture2D u_depthTex;
layout(set = 0, binding = 3) uniform texture2D u_gbuffer2Tex;
layout(set = 0, binding = 4) writeonly uniform image2D u_outImg[2];

layout(std140, push_constant, row_major) uniform b_pc
{
	Mat4 u_invViewProjMat;
	Vec3 m_padding;
	F32 u_time;
};

Vec3 unproject(Vec2 ndc, F32 depth)
{
	const Vec4 worldPos4 = u_invViewProjMat * Vec4(ndc, depth, 1.0);
	const Vec3 worldPos = worldPos4.xyz / worldPos4.w;
	return worldPos;
}

void main()
{
	// Set UVs
	ANKI_BRANCH if(gl_GlobalInvocationID.x >= OUT_IMAGE_SIZE.x || gl_GlobalInvocationID.y >= OUT_IMAGE_SIZE.y)
	{
		// Out of bounds
		return;
	}

	const Vec2 uv = (Vec2(gl_GlobalInvocationID.xy) + 0.5) / Vec2(OUT_IMAGE_SIZE);

	// Reference
	Vec4 color0 = textureLod(u_inTex, u_linearAnyClampSampler, Vec3(uv, 0.0), 0.0);
	Vec4 color1 = textureLod(u_inTex, u_linearAnyClampSampler, Vec3(uv, 1.0), 0.0);
	F32 weight = 1.0;

	BilateralSample ref;
	ref.m_depth = textureLod(u_depthTex, u_linearAnyClampSampler, uv, 0.0).r;
	ref.m_position = unproject(UV_TO_NDC(uv), ref.m_depth);
	ref.m_normal = readNormalFromGBuffer(u_gbuffer2Tex, u_linearAnyClampSampler, uv);

	// Sample
	SpatialBilateralContext ctx =
		spatialBilateralInit(SAMPLE_COUNT, gl_GlobalInvocationID.xy, PIXEL_RADIUS, SPIRAL_TURN_COUNT, u_time);

	for(U32 i = 0; i < SAMPLE_COUNT; ++i)
	{
		const IVec2 unormalizedUvs = clamp(IVec2(spatialBilateralIterate(ctx, i)), IVec2(0), IVec2(OUT_IMAGE_SIZE - 1));
		const Vec2 sampleUv = Vec2(unormalizedUvs) / Vec2(OUT_IMAGE_SIZE);

		BilateralSample crnt;
		crnt.m_depth = texelFetch(u_depthTex, unormalizedUvs, 0).r;
		crnt.m_position = unproject(UV_TO_NDC(sampleUv), crnt.m_depth);
		crnt.m_normal = unpackNormalFromGBuffer(texelFetch(u_gbuffer2Tex, unormalizedUvs, 0));

		BilateralConfig config;
		const Vec3 weights = normalize(Vec3(0.0, 1.0, 0.0));
		config.m_depthWeight = weights.x;
		config.m_normalWeight = weights.y;
		config.m_planeWeight = weights.z;
		config.m_roughnessWeight = 0.0;
		const F32 w = calculateBilateralWeight(crnt, ref, config);
		weight += w;

		const Vec4 sampleColor0 = texelFetch(u_inTex, IVec3(unormalizedUvs / 2, 0), 0);
		const Vec4 sampleColor1 = texelFetch(u_inTex, IVec3(unormalizedUvs / 2, 1), 0);
		color0 += sampleColor0 * w;
		color1 += sampleColor1 * w;
	}

	color0 /= weight;
	color1 /= weight;

	// Write value
	imageStore(u_outImg[0], IVec2(gl_GlobalInvocationID.xy), color0);
	imageStore(u_outImg[1], IVec2(gl_GlobalInvocationID.xy), color1);
}

#pragma anki end
